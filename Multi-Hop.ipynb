{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai fastembed langchain oxrdflib qdrant-client"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T16:08:11.199632900Z",
     "start_time": "2024-03-27T16:08:09.081217100Z"
    }
   },
   "id": "41b9b7eb0c5bb117",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T16:08:52.415055600Z",
     "start_time": "2024-03-27T16:08:45.287247500Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from typing import Any, List, Optional\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import format_document\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Provide your OpenAI API Key\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "extract_classes_query = \"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "\n",
    "SELECT ?uri ?predicate ?label ?type\n",
    "WHERE {\n",
    "    ?uri a ?type;\n",
    "        ?predicate ?label.\n",
    "    FILTER (\n",
    "        ?predicate = schema:name\n",
    "    )\n",
    "}\"\"\"\n",
    "\n",
    "class OntologyLoader(BaseLoader):\n",
    "    \"\"\"Load an OWL ontology and extract classes and properties as documents.\"\"\"\n",
    "\n",
    "    def __init__(self, ontology_url: str, format: Optional[str] = None):\n",
    "        self.ontology_url = ontology_url\n",
    "        self.format = format\n",
    "        self.graph = Graph(store=\"Oxigraph\")\n",
    "        self.graph.parse(source=self.ontology_url, format=self.format)\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load and return documents (classes and properties) from the OWL ontology.\"\"\"\n",
    "        docs: List[Document] = []\n",
    "        for cls in self.graph.query(extract_classes_query):\n",
    "            docs.append(self._create_document(cls))\n",
    "        return docs\n",
    "\n",
    "    def _create_document(self, result_row: Any) -> Document:\n",
    "        \"\"\"Create a Document object from a query result row.\"\"\"\n",
    "        label = str(result_row.label)\n",
    "        return Document(\n",
    "            page_content=label,\n",
    "            # NOTE: you can include more metadata retrieved by the SPARQL query here\n",
    "            metadata={\n",
    "                \"label\": label,\n",
    "                \"uri\": str(result_row.uri),\n",
    "                \"type\": str(result_row.type),\n",
    "                \"predicate\": str(result_row.predicate),\n",
    "                \"ontology\": self.ontology_url,\n",
    "            },\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T16:08:53.373152300Z",
     "start_time": "2024-03-27T16:08:53.367507600Z"
    }
   },
   "id": "2f7848c4edeb02e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a84e0ddd51a14ec0a0b622d3d3d5990f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flag_embeddings = FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\", max_length=512)\n",
    "loader = OntologyLoader(\"football_data.ttl\", format=\"ttl\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    splits,\n",
    "    flag_embeddings,\n",
    "    collection_name=\"ontologies\",\n",
    "    location=\":memory:\",\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "llm = OpenAI(temperature=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T16:11:01.558492Z",
     "start_time": "2024-03-27T16:10:03.928427500Z"
    }
   },
   "id": "27313d478b125cdb",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def reformulate_question(question: str, llm) -> str:\n",
    "    \"\"\"\n",
    "    Reformulate the question to include necessary contextual information.\n",
    "    \"\"\"\n",
    "    reformulation_prompt = f\"\"\"\n",
    "    Reformulate the question such that it explicitly mentions additionally required information. Only reformulate the question if the original question is not specific enough to answer.\n",
    "    Question: {question}\n",
    "    Standalone question:\"\"\"\n",
    "    reformulated_question = llm.generate([reformulation_prompt], max_tokens=200)\n",
    "    return reformulated_question.generations[0][0].text\n",
    "\n",
    "def generate_answer(context: str, question: str, llm) -> str:\n",
    "    \"\"\"\n",
    "    Generate an answer using the retrieved documents as context.\n",
    "    \"\"\"\n",
    "    answer_prompt = f\"\"\"\n",
    "    Answer the question as a list by giving all that is asked for in csv format. Do not give information simply because it is related to the question. If you cannot answer the question, say so. Do not use any information outside this context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    answer = llm.generate([answer_prompt], max_tokens=100)\n",
    "    return answer.generations[0][0].text\n",
    "\n",
    "# Format how the ontology concepts are passed as context to the LLM\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(\n",
    "    template=\"Concept label: {page_content} | URI: {uri} | Type: {type} | Predicate: {predicate} | Ontology: {ontology}\"\n",
    ")\n",
    "def combine_documents(docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    # print(\"Formatted docs:\", doc_strings)\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "def ask_question(question: str, retriever, llm) -> str:\n",
    "    \"\"\"\n",
    "    Ask a question to the RAG system and return the generated answer.\n",
    "    \"\"\"\n",
    "    reformulated_question = reformulate_question(question, llm)\n",
    "    print(\"Reformulated question:\", reformulated_question)\n",
    "    docs = retriever.get_relevant_documents(reformulated_question)\n",
    "    context = combine_documents(docs)\n",
    "    answer = generate_answer(context, reformulated_question, llm)\n",
    "    return answer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T16:29:25.137867400Z",
     "start_time": "2024-03-27T16:29:25.134098900Z"
    }
   },
   "id": "2b4204269bdb3bc",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question Answering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c5566b64bc78c78"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformulated question:  What are the names of Croatian players who have won a UEFA Champions League, played for Real Madrid, and scored more than 10 goals in the tournament?\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nLuka Modrić, Mateo Kovačić, and Ivan Rakitić'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Names of Croatian players who won a UEFA Champions League, played for Real Madrid, and scored more than 10 goals in the tournament.\"\n",
    "answer = ask_question(question, retriever, llm)\n",
    "answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T16:29:27.550932400Z",
     "start_time": "2024-03-27T16:29:25.738727Z"
    }
   },
   "id": "65e17ff6c47422a5",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e5ea703c1fdc843"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
